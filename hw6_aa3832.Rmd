---
title: "p8105 hw6"
author:  "Alexey Abramov"
date: "12/8/2020"
output: 
  github_document:
    toc: true
---

# Setup

```{r, setup}
library(tidyverse)
library(readr)
library(plotly)
library(purrr)
library(broom)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.height = 6,
  out.width = "90%"
)

theme_set(
  ggthemes::theme_fivethirtyeight() + theme(legend.position = "bottom")
  )

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.colour = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Loading the data.

Here we are able to filter race to black and white, for better understanding the regression

# Problem 1

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    victim_age = as.numeric(victim_age),
    city_state = str_c(city, state, sep = "_"),
    resolution = case_when(
      disposition == "Closed without arrest"  ~ 0,
      disposition == "Open/No arrest"         ~0,
      disposition == "Closed by arrest"      ~1)) %>% 
  filter(
    city_state != "Tulsa_AL",
    victim_race %in% c("White", "Black")) %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

## Data wrangling
So now the regression is alphabetical with the predictor variables.

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore_MD")

glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy()
```

Fixing it up, looking clean

```{r}
baltimore_df =
  homicide_df %>% 
  filter(city_state == "Baltimore_MD")

glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 3)
```

Trying this across multiple cities now.
Here we are mapping across our dataframe (.x  = data), and then (data = .x) appears later in the argument.

Then we create a results column which has the broom tidy output from the model call, and then we will unnest it.

```{r}
model_results_df = homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x,
    family = binomial())),
    results = map(models, broom::tidy)
    ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)) %>% 
  select(city_state, term, OR, starts_with("CI"))
  
```

## Odds Ratio Plot Across 50 Cities

```{r}
model_results_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```

# Problem 2

tips and tricks
Start with the models and then perform cross-validation 

Model building, look at the p values, residuals, 

## Cleaning up the data.  

I first looked up the poverty level for a family of three in the Dept HHS 2018 guidelines, which was $20,780 per year and so that's approx $1800 per month.  

I wanted to consider a 'poverty' variable, but looks like this dataset doesn't quite represent a true population of American households as very few have a monthly income that's <$1800 per month. 

```{r}
baby_df = 
  read_csv("./birthweight_data/birthweight.csv") %>% 
  mutate(
    babysex = as.factor(babysex),
    malform = as.factor(malform),
    poverty = case_when(
      fincome <18  ~ 1,
      fincome >18  ~ 0),
    poverty = as.factor(poverty))
```

So instead, maybe I'll just take a look at the summary here and see about families in the lowest quartile vs. others.  

```{r}
baby_df %>% pull(fincome) %>% summary()
```

Might also be a good idea to just see a summary of birthweights in general.  

```{r}
baby_df %>% pull(bwt) %>% summary()
baby_df %>% pull(bwt) %>% mean()
```

Ok, so looking at a median and mean around 3100. 

```{r}
baby_df = 
  read_csv("./birthweight_data/birthweight.csv") %>% 
  mutate(
    babysex = as.factor(babysex),
    malform = as.factor(malform),
    poverty = case_when(
      fincome <25  ~ 1,
      fincome >25  ~ 0),
    poverty = as.factor(poverty))
```

Ok, I think this may be more reasonable for a model to consider a poverty level that includes families in the lowest quartile of family income. 

## Plots to consider


Plots to consider

```{r}
baby_df %>% 
  ggplot(aes(x = poverty, y = bwt)) +
  geom_violin() + 
  labs(title = "poverty")
```
About similar, slightly lower birthweight in the poverty cohort.

```{r}
baby_df %>% 
  ggplot(aes(x = momage, y = bwt)) +
  geom_point() + 
  labs(title = "mom age")
```
Interesting, a lot of variability in young mothers and then looks like slightly lower birthweight in older mothers.  

```{r}
baby_df %>% 
  filter(smoken > 0) %>% 
  ggplot(aes(x = smoken, y = bwt)) +
  geom_point() + 
  labs(title = "smoking")
```
Filtered out non-smokers for the purposes of the plot, looks again like maybe more smoking suggests lower birthweight.  

```{r}
baby_df %>% 
  filter(smoken > 0) %>% 
  ggplot(aes(x = gaweeks, y = bwt)) +
  geom_point() + 
  labs(title = "ga age")
```
This is a clear relatiosnhip that's fairly well known,  Premature babies tend to be smaller in size.  

## Building a model

### take 1

```{r}
poverty_model = lm(bwt ~ poverty + momage, data = baby_df) 

poverty_model %>%  
  broom::tidy()  %>% 
  select(term, estimate, p.value)
```

Both of these predictors appear to be quite significant.  

Will add residuals and plot it here now.  

```{r}
baby_df %>% 
  modelr::add_residuals(poverty_model) %>% 
  ggplot(aes(x = bwt, y = resid)) +
  geom_point() +
  labs(
    title = "poverty model residuals plot")
```

Residuals plot looks pretty darn linear, which suggests this is a terrible model. The residuals for max and min outliers are quite extreme.  

```{r}
summary(poverty_model) 
```

And yes, just to reconfirm, the adjusted Rsquared value is awful at 0.03 in the poverty_model.  

Here is the predictions plot.

```{r}
baby_df %>% 
  modelr::add_predictions(poverty_model) %>% 
  ggplot(aes(x = bwt, y = pred)) +
  geom_point()
```

Based on these data,I would certainly not use my model to predict birthweight based on a definition of poverty as family income in the lowest quartile and mother's age.  


### take 2

Let's try again with something more standardized, I'll make a model considering the mother's weight at deliviery, as well as her weight gain, over the period of gestational age, in weeks. 

```{r}
weight_model= lm(bwt ~ delwt + wtgain + gaweeks, data = baby_df) 

weight_model %>%  
  broom::tidy()  %>% 
  select(term, estimate, p.value)
```

```{r}
summary(weight_model)
```

```{r}
baby_df %>% 
  modelr::add_residuals(weight_model) %>% 
  ggplot(aes(x = bwt, y = resid)) +
  geom_point() +
  labs(
    title = "weight model residuals plot")
```

Still pretty linear appearing but at least it's better than the poverty model.  I'll plan to keep this one.  I recognize the problems with the model in that's I'm focusing on the gestational factors because it seems be pretty clear that a baby's head circumference and their length are likely related to the baby's weight!  

## Building the two other models in this assignment for consideration.

```{r}
predictor_model_1 = 
  lm(bwt ~ blength + gaweeks, data = baby_df)

predictor_model_1 %>% 
  broom::tidy()

summary(predictor_model_1)
```

```{r}
predictor_model_2 = 
  lm(bwt ~ bhead + blength + babysex, data = baby_df)

predictor_model_2 %>% 
  broom::tidy()

summary(predictor_model_2)
```

Clearly, these two models that include the baby are better than mine. 

Ok, now will move on to cross-validating these models and comparing.

```{r}
cv_df = 
  crossv_mc(baby_df, 4000) 
```

Creating the cross-validation and rmse calls here.  

```{r}
cv_df = 
  cv_df %>% 
  mutate(
    weight_model  = 
      map(train, ~lm(bwt ~ delwt + wtgain + gaweeks, data = .x)),
    predictor_model_1  = 
      map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    predictor_model_2  = 
      map(train, ~lm(bwt ~ bhead + blength + babysex, data = .x))) %>% 
  mutate(
    rmse_weight = map2_dbl(weight_model, test, ~rmse(model = .x, data = .y)),
    rmse_pred1 = map2_dbl(predictor_model_1, test, ~rmse(model = .x, data = .y)),
    rmse_pred2 = map2_dbl(predictor_model_2, test, ~rmse(model = .x, data = .y)))
```

Plotting the cv and RMSE here.

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

Very cool! The plots worked out well here and we can appreciate that the prediction model 2 with  head circumference, length, and baby sex generates the lowest RMSEs and therefore the best model of the three proposed with consideration to cross-validation with the training and testing datasets.  

# Problem 3

```{r}

```

